{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "786f1163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "from time import time, strftime, gmtime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose, Normalize\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from loss_functions import *\n",
    "from train_test import train, test\n",
    "from noise import AddGaussianNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb4b8873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "sigma = 0.0   # Standard error for feature noise\n",
    "eta   = 0.0   # Probability of no change for label noise \n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "# 100 features\n",
    "# 10 classes\n",
    "\n",
    "train_data = torch.load('data-sub/train_data-sigma{}_eta{}'.format(sigma,eta))\n",
    "test_data = torch.load('data-sub/test_data-sigma{}_eta{}'.format(sigma,eta))\n",
    "\n",
    "# Create data loaders\n",
    "batch_size_train = 64\n",
    "batch_size_test  = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size_train, shuffle=True)\n",
    "test_dataloader  = DataLoader(test_data,  batch_size=batch_size_test,  shuffle=True)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d29368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=300, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=300, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Define models\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(28*28, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.layers(x)\n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95bc2cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train_dataloader, test_dataloader, model, loss_fn, optimizer, epochs):\n",
    "\n",
    "    train_loss0 = []\n",
    "    train_acc0  = []\n",
    "\n",
    "    train_loss = []\n",
    "    train_acc  = []\n",
    "    test_loss  = []\n",
    "    test_acc   = []\n",
    "\n",
    "    tr_ls, tr_ac = test(train_dataloader, model, loss_fn)\n",
    "    train_loss.append(tr_ls)\n",
    "    train_acc.append(tr_ac)\n",
    "\n",
    "    te_ls, te_ac = test(test_dataloader, model, loss_fn)\n",
    "    test_loss.append(te_ls)\n",
    "    test_acc.append(te_ac)\n",
    "\n",
    "    for t in tqdm(range(epochs)):\n",
    "        #print(f\"Epoch {t+1}\")\n",
    "\n",
    "        tr_ls0, tr_ac0 = train(train_dataloader, model, loss_fn, optimizer)\n",
    "        train_loss0.extend(tr_ls0)\n",
    "        train_acc0.extend(tr_ac0)  \n",
    "\n",
    "        tr_ls, tr_ac = test(train_dataloader, model, loss_fn)\n",
    "        train_loss.append(tr_ls)\n",
    "        train_acc.append(tr_ac)\n",
    "\n",
    "        te_ls, te_ac = test(test_dataloader, model, loss_fn)\n",
    "        test_loss.append(te_ls)\n",
    "        test_acc.append(te_ac)\n",
    "\n",
    "        #print(f\"Test accuracy: {(100*te_ac):>0.1f}%, Test loss: {te_ls:>8f}\")\n",
    "        \n",
    "    return train_loss0, train_acc0, train_loss, train_acc, test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fdd4ef3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Experiment: 0/1***\n",
      "MSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [04:01<00:00, 12.05s/it]\n",
      "/opt/anaconda/lib/python3.9/site-packages/numpy/core/_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n",
      "100%|███████████████████████████████████████████| 20/20 [03:52<00:00, 11.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [03:52<00:00, 11.63s/it]\n",
      "100%|███████████████████████████████████████████| 20/20 [03:55<00:00, 11.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [03:58<00:00, 11.92s/it]\n",
      "100%|███████████████████████████████████████████| 20/20 [04:05<00:00, 12.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher-Rao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [03:57<00:00, 11.89s/it]\n",
      "100%|███████████████████████████████████████████| 20/20 [04:00<00:00, 12.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [03:59<00:00, 11.98s/it]\n",
      "100%|███████████████████████████████████████████| 20/20 [04:01<00:00, 12.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 00:40:48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create folder\n",
    "if not os.path.exists('results-lr/'):\n",
    "    os.mkdir('results-lr/')\n",
    "    \n",
    "def my_MSE_loss(x,y):\n",
    "    return MSE_loss(x,y,10)\n",
    "\n",
    "def my_MAE_loss(x,y):\n",
    "    return MAE_loss(x,y,10)\n",
    "\n",
    "Loss_fn = [my_MSE_loss, my_MAE_loss, CE_loss, FR_loss, H_loss]\n",
    "titles  = ['MSE', 'MAE', 'Cross-entropy', 'Fisher-Rao', 'Hellinger']\n",
    "\n",
    "n_trials = 1\n",
    "epochs   = 20\n",
    "\n",
    "# All learning rates for all losses\n",
    "Lr_all   = [[1, 4] for ii in range(5)]\n",
    "# One learning rate per loss\n",
    "#Lr_all   = [[0.1], [0.5], [0.005], [0.01], [0.01]]\n",
    "\n",
    "# For each experiment (trial)\n",
    "for i_trial in range(n_trials):\n",
    "    \n",
    "    tic = time()\n",
    "    \n",
    "    print('\\n***Experiment: {}/{}***'.format(i_trial,n_trials))\n",
    "\n",
    "    # Choose loss function\n",
    "    for i_loss in range(len(Loss_fn)):\n",
    "        \n",
    "        loss_fn = Loss_fn[i_loss]\n",
    "        print(titles[i_loss])\n",
    "        \n",
    "        # Choose learning rate\n",
    "        for lr in Lr_all[i_loss]:\n",
    "        \n",
    "            model = NeuralNetwork().to(device)\n",
    "\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "            train_loss0, train_acc0, train_loss, train_acc, test_loss, test_acc\\\n",
    "                    = run(train_dataloader, test_dataloader, model, loss_fn, optimizer, epochs)\n",
    "\n",
    "            filename = 'results-lr/mnist_{}_lr{}_eta{}_trial{}'.format(titles[i_loss],lr,eta,i_trial)\n",
    "            np.save(filename, [train_loss0, train_acc0, train_loss, train_acc, test_loss, test_acc])\n",
    "        \n",
    "    toc = time()\n",
    "    print('Elapsed time: ' + strftime(\"%H:%M:%S\", gmtime(toc-tic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b59e76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
